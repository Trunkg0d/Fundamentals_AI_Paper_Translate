# Multimodal Classification: Current Landscape, Taxonomy and Future Directions
[WILLIAM C.SLEEMAN IV, RISHABH KAPOOR], and [PREETAM GHOSH],
Virginia Commonwealth University, USA

Nghiên cứu về Multimodal Classification đã đạt được nhiều thành tựu trên những bộ dữ liệu mới trong nhiều lĩnh vực khác nhau như hình ảnh vệ tinh, sinh trắc học, y tế. Những nghiên cứu trước đã chỉ ra lợi ích của việc kết hợp dữ liệu từ nhiều nguồn so với dữ liệu unimodal truyền thống đã dẫn đến sự phát triển của nhiều cấu trúc multimodal chưa từng có trước đây. Tuy nhiên, việc thiếu nhất quán các thuật ngữ và mô tả về kiến trúc gây không ít khó khăn cho việc so sánh khác giải pháp với nhau. Chúng tôi đối mặt với thách thức đó bằng việc đề xuất một cách thức phân loại mới để mô tả những mô hình multimodal classification dựa trên các xu hướng được tìm thấy trong các công bố gần đây. Các ví dụ về cách phân loại này có thể được áp dụng trong các mô hình hiện có mà đã được trình bày và cũng được xem như là một danh sách để hỗ trợ trình bày một cách rõ ràng và đầy đủ các mô hình trong tương lai. Nhiều khía cạnh khó nhất của unimodal classification vẫn chưa được giải quyết một cách đầy đủ cho các bộ dữ liệu multimodal bao gồm cả dữ liệu lớn (big data), sự mất cân đối lớp (class imbalance) và sự khó khăn trong việc phân loại từng trường hợp cụ thể trong tập dữ liệu (instance-level difficulty). Chúng tôi sẽ thảo luận về những thách thức này và những hướng nghiên cứu trong tương lai.
## GIỚI THIỆU (INTRODUCTION)
Trong thập kỷ qua, đã có sự tập trung tăng cường vào việc kết hợp dữ liệu từ nhiều phương thức khác nhau để cải thiện các mô hình phân loại dựa trên học máy (machine learning). Dữ liệu đang trở nên quan trọng hơn đối với mọi ngành công nghiệp và nghiên cứu, điều này dẫn đến việc tạo ra các tập dữ liệu lớn và đa dạng hơn. Tốc độ thu thập dữ liệu ngày càng tăng và những lợi ích được báo cáo của dữ liệu đa phương tiện (multimodal data) cho các mô hình học máy (machine learning) đã thúc đẩy sự quan tâm cho lĩnh vực này. Bằng cách sử dụng thông tin từ nhiều biểu diễn của cùng một chủ đề, một bức tranh hoàn chỉnh hơn về vấn đề đang được giải quyết có thể được xây dựng. Dữ liệu trên đa lĩnh vực có thể được biểu diễn một cách tự nhiên trong nhiều lĩnh vực vấn đề như y tế [27, 35, 40, 49], hình ảnh siêu không gian [7, 30], phân tích cảm xúc [14, 83, 89] và nhiều lĩnh vực khác.

Đa số các thuật toán phân loại hiện nay được thiết kế cho các tập dữ liệu đơn phương tiện (unimodal datasets), đại diện cho một nguồn dữ liêu duy nhất cho mỗi vấn đề cụ thể. Những tập dữ liệu này thường chỉ sử dụng một loại dữ liệu như bảng, hình ảnh, hoặc văn bản nhưng nhiều tình huống trong thực tế bao gồm dữ liệu của nhiều loại khác nhau. Các tập dữ liệu dự đoán giá có thể bao gồm cả văn bản từ các bài báo và dữ liệu bảng từ các báo cáo tài chính, hoặc hồ sơ y tế có thể có cả dữ liệu giám sát tim dựa trên tín hiệu và chẩn đoán hình ảnh. Việc kết hợp các phương thức dữ liệu có thể gặp thách thức khi mà mỗi biểu diễn riêng đều khác biệt đáng kể so với dữ liệu đã kết hợp như là hình ảnh-văn bản, âm thanh-video, hoặc nhiều cảm biến không đồng bộ theo thời gian. Những thách thức đó dẫn đến những giải pháp sử dụng các thuật toán đơn phương tiện (unimodal algorithms) để giải quyết các vấn đề đa phương tiện (multimodal problems).

Học đa phương tiện (multimodal learning) ngày càng được quan tâm dẫn đến một số lượng các bài khảo sát gần đây bao phủ toàn bộ các lĩnh vực [9, 59, 122, 124], với nhiều bài khảo sát tập trung vào lĩnh vực học sâu (deep learning) [32, 77, 115], giải pháp cụ thể cho từng lĩnh vực [7, 27, 29], hoặc các phương pháp không phân loại [35, 49, 78]. Mặc dù những công trình này bao phủ sự rộng lớn của học đa phương tiện (multimodal learing), nhưng không có bất kỳ bài khảo sát nào cụ thể đi nghiên cứu các vấn đề phân loại hay các thuộc tính đặc trưng của chúng.  Bài báo này được dẫn dắt bởi các vấn đề sau:
	(1) **Thiếu một hệ thống phân loại cụ thể cho phân loại đa phương tiện**
	Mặc dù đã có nhiều hệ thống phân loại được trình bày trước đây, nhưng chúng được hướng đến việc học đa phương tiện (multimodal learning) toàn diện thay vì phân loại. Ví dụ, công trình của Baltrušaitis và cộng sự [9] đề cập đến nhiều lại học như chú thích hình ảnh (image captioning), mô tả video (video description), chuyển đổi văn bản thành hình ảnh (text-to-image conversions), đồng huấn luyện (co-traning), học chuyển tiếp (transfer learning) và học không cần ví dụ (zero-shot learning).  Mặc dù hệ thống phân loại đó có thể được áp dụng cho hầu như bất kỳ vấn đề đa phương tiện (multilmodal problem) nào, nhưng nó không đủ cụ thể để mô tả đầy đủ các kiến trúc phân loại đa phương tiện (multimodal classfification) gần đây.
	(2) **Xác định xu hướng gần đây trong kiến trúc mô hình**
	Vì các bài khảo sát trước đây đã tập trung vào các khía cạnh cấp cao của học đa phương tiện (multimodal learning) hoặc các vấn đề cụ thể cho từng lĩnh vực, do đó chưa có một bài đánh giá về các mô hình phân loại gần đây và kiến trúc của chúng. Việc so sánh các kiến trúc là cần thiết để xác định xu hướng hiện tại và cách chúng có thể được mô tả bằng một hệ thống phân loại chung.
	(3) **Cung cấp một cách để mô tả kiến trúc phân loại đa phương tiện (multimodal classificaiton)**
	Trong quá trình xem xét các bài báo về phân loại đa phương tiện (multimodal classification), chúng tôi nhận thấy rằng cần một lượng công việc đáng kể để phân rã nhiều kiến trúc mô hình. Mỗi mô hình sử dụng bộ thuật ngữ và phương thức trình bày riêng, vì vậy việc xem xét từng bài báo là một trải nghiệm mới khiến quá trình này khó khăn hơn. Đi cùng hệ thống phân loại, cần có một khung mô tả chung để làm cho việc mô tả và so sánh các kiến trúc mô hình trở nên dễ dàng hơn.
	(4) **Thảo luận về các thách thức trong tương lai**
	Các vấn đề liên quan đến dữ liệu lớn (big data), tính toán phân tán (distributed computing), và các tập dữ liệu khó đã được nghiên cứu kỹ lưỡng với các vấn đề đơn phương tiện (unimodal problems), nhưng vẫn còn hạn chế trong học đa phương tiện (multimodal learning). Cần có một cuộc thảo luận về các thách thức này có thể ảnh hưởng đến phân loại đa phương tiện (multimodal classification) như thế nào.

Phần còn lại của bài báo được tổ chức như sau: Phần 2 cung cấp một cái nhìn tổng quát  cho học đa phương tiện (multimodal learning) và ví dụ về các giải pháp trong từng lĩnh vực cụ thể hiện có. Phần 3 đưa ra các mô tả về kiến trúc phân loại đa phương tiện (multimodal classification) và hệ thống phân loại mà chúng tôi đã đề xuất, và phần 4 xem xét nghiên cứu phân loại đa phương tiện (multimodal classification) gần đây sử dụng những thuật ngữ chung, thứ sẽ giải quyết vấn đề 1 và 2 ở trên. Phần 5 đưa ra các ví dụ về cách áp dụng hệ thống phân loại cho cả các mô hình hiện có và tương lại trong vấn đề 3. Phần 6 thảo luận về những thách thức với việc phân loại mà chưa được giải quyết cho các vấn đề đa phương tiện (multimodal problems) đã nêu trong vấn đề 4. Cuối cùng, Phần 7 cung cấp những nhận xét kết luận của chúng tôi. Trong bảng 1, chúng tôi giới thiệu một danh sách các từ viết tắt sẽ được sử dụng thường xuyên trong phần còn lại của bài viết này.
![[Translate_paper/Tan/images/1.png]]
## Các nghiên cứu đa phương tiện trước đây
Lợi ích tiềm năng của việc sử dụng thông tin từ nhiều nguồn dữ liệu đã dẫn đến nhiều bài báo gần đây tập trung vào học đa phương tiện (multimodal learning). Trong phần này, chúng tôi xem xét các khái niệm cốt lõi của học đa phương tiện, phân loại và nghiên cứu cụ thể theo lĩnh vực. 
*Tuy nhiên, trước hết chúng tôi phải thảo luận về các thuật ngữ đa phương tiện (multimodal) và đa quan điểm (multi-view), vì cả hai đều thường được sử dụng trong văn bản. Những thuật ngữ này thường được sử dụng thay thế như là các hệ thống học tập kết hợp thông tin từ nhiều nguồn, thường để phân biệt với các vấn đề truyền thống sử dụng một nguồn dữ liệu duy nhất (đơn phương tiện). Mặc dù những thuật ngữ này được sử dụng để mô tả các mô hình học tập kết hợp rõ ràng nhiều nguồn dữ liệu, đa quan điểm dường như được liên kết phổ biến hơn với các loại thuật toán khác nhau, chẳng hạn như đồng đào tạo [92, 124], Phân tích Tương quan Chuẩn (CCA) -dựa trên truy xuất chéo-modality [59, 124], giám sát bán [124], gom nhóm [15, 50], lựa chọn tính năng không giám sát [99, 100], và học không gian con [110].* 
Vì lý do nhất quán, chúng tôi đã chọn sử dụng thuật ngữ đa phương tiện để mô tả các thuật toán học tập bao gồm thông tin từ nhiều nguồn dữ liệu với mục đích cải thiện hiệu suất dự đoán. Các trường hợp sử dụng khác, chẳng hạn như học chuyển giao hoặc đào tạo cùng nhau, sau đó có thể được mô tả là đa quan điểm để cung cấp một số sự phân biệt giữa những cách tiếp cận học này. Trong khi chúng tôi tin rằng những định nghĩa này sẽ hữu ích cho cộng đồng nghiên cứu, sẽ cần thêm thảo luận để hình thành một sự thống nhất.
### Khái niệm đa phương tiện
Một số khảo sát đã xác định đồng đào tạo (co-training) [92, 110, 124] và đồng điều chỉnh (co-regularization) [92, 124] là các hạng mục chính của học đa phương tiện (multimodal learning). Đồng đào tạo được sử dụng trong các vấn đề bán giám sát khi có sự kết hợp của dữ liệu có nhãn và không có nhãn, nơi kiến thức từ một phương tiện (modality) có thể được sử dụng để hỗ trợ một mô hình được đào tạo trên một phương tiện khác. Các ứng dụng tiềm năng của đồng đào tạo bao gồm học không qua giám sát, học chuyển tiếp và ghi chú các ví dụ không có nhãn. Đồng điều chỉnh biến đổi từng phương tiện để đảm bảo rằng chúng tương thích. Điều này có thể được thực hiện với các kỹ thuật như CCA hoặc hiệu chỉnh các bộ phân loại cụ thể cho phương tiện. 
Một công trình toàn diện hơn đã được trình bày bởi Baltrušaitis và cộng sự [9] rằng đã xác định năm thách thức với học đa phương tiện: biểu diễn (representation) [9, 122], dịch (translation) [9], căn chỉnh (alignment) [9, 59, 92], hợp nhất (fusion) [9, 59, 92, 122], và đồng học tập (co-learning) [9, 124]. Một số nhiệm vụ học đa phương tiện khác cũng đã được nghiên cứu bao gồm học bán giám sát [92, 110, 124], mã hóa [25], gom nhóm [92, 124], và học đa nhiệm (multi-task learning) [55, 124]. Mặc dù nhiều khảo sát này giải quyết các khía cạnh của các vấn đề phân loại, chẳng hạn như căn chỉnh và hợp nhất, nhưng chúng thường bao gồm một phạm vi rộng lớn các chủ đề. 
### Mô hình phân loại
Nhiều bài báo đã trình bày các hệ thống phân loại, thường nhắm vào các vấn đề thuộc lĩnh vực cụ thể. Di Mitri và cộng sự [19] đã nghiên cứu việc sử dụng dữ liệu đa phương tiện (multimodal data) để học các hành vi của con người sử dụng cảm biến. Một hệ thống phản hồi được gọi là Mô hình Phân tích Học tập Đa phương tiện (Mulltimodal Learning Analysis Model - MLeAM)  sử dụng dữ liệu cảm biến đa phương tiện, chú thích thủ công và học máy để hướng dẫn các thay đổi về hành vi. Các tác giả cũng cung cấp một hệ thống phân loại dạng cây mô tả các nguồn dữ liệu khác nhau có thể thu thập được từ cảm biến. Garcia-Ceja và cộng sự [27] cũng đã đánh giá các hệ thống dựa trên cảm biến dùng để giải quyết các vấn đề về sức khỏe tinh thần. Hệ thống phân loại của họ đề cập đến loại nghiên cứu, thời gian nghiên cứu và các loại cảm biến.

Yan và cộng sự [15] đã đánh giá các phương pháp đa phương tiện (multimodal methods) trong bối cảnh của học sâu. Hệ thống phân loại của họ phân biệt các thuật toán phụ thuộc vào việc chúng có thuộc về học sâu (tức là CNN, GAN) hay là các kỹ thuật học máy truyền thống đã được chiều chỉnh để phù hợp với học sâu (tức là CCA, spectal clusstering). Bài đánh giá của họ cũng thảo luận về các chiến lược mạng khác nhau, bộ mã tự động hai chiều (bimodal auto-encoders) và các phương pháp dựa trên GAN.

Jiang và cộng sự [49] đã cung cấp một bài đánh giá toàn diện về các kỹ thuật matching hay registration cho đa phương tiện hình ảnh, nó liên kết cùng một khái niệm qua nhiều hình ảnh. Họ cũng đã xác định được hai lớp chính của các giải pháp: image registration dựa trên khu vực và dựa trên đặc trưng. Sử dụng thống tin cường độ của toàn bộ ảnh để tìm các vùng khớp,  các phương pháp dựa trên vùng (area) tạo ra các biến đổi có thể được sử dụng trong việc image registration. Các phương pháp registration dựa trên đặc trưng bao gồm phát hiện đặc trưng (feature detection) (góc, blob và đặc trưng có thể học), mô tả đặc trưng (feature description) (float, nhị phân, và mô tả có thể học) và khớp đặc trưng (feature matching) (graph matching, point set registration, các phương pháp gián tiếp).

Ramachandram và Taylor [77] đã cung cấp một hệ thống phân loại kèm theo bài đánh giá về nghiên cứu đa phương tiện học sâu. Trong hệ thống phân loại của họ, các mô hình được mô tả bằng các phương tiện đầu vào, problem space, fusion method, loại mô hình và kiến trúc. Các phương tiện đầu vào bao gồm âm thanh, video, hình ảnh, văn bản và các phương tiện khác cụ thể cho lĩnh vực y tế. Problem space bao gồm các lĩnh vực như nhận dạng hành động, chẩn đoán y tế và nắm bắt robot. Fusion method mô tả cách dữ liệu từ từng phương tiện được kết hợp và sử dụng các thuật ngữ *early, intermediate* và *late*. Loại mô hình là *generative* hoặc *discriminate*, với kiến trúc được xác định là mô hình thực sự được sử dụng, chẳng hạn như CNN, RNN hoặc LSTM.

Tiếp theo, chúng tôi sẽ cung cấp một cái nhìn tổng quan, ngắn gọn về hệ thống phân loại đa phương tiện được đề xuất bởi Baltrušaitis và cộng sự [9] bao gồm các khái niệm học về representation, translation, alignment, fusion và co-learning.

**Representation** được mô tả là cách dữ liệu từ từng phương tiện được biểu diễn dưới dạng vector đặc trưng. Vì dữ liệu có thể là văn bản, hình ảnh hoặc video, sự không đồng nhất có thể tạo thêm sự phức tạp cho các learning models. Các thách thức về representation được gom lại thành *Joint* hoặc *Coordinated*. 
*Joint representation*s kết hợp dữ liệu từ nhiều phương tiện để tạo ra một biểu diễn duy nhất. Điều này có thể được thực hiện với các mạng nơ-ron bằng cách nối các lớp cụ thể cho phương tiện để tạo ra một lớp ẩn (hidden layer) mới. Các mô hình đồ thị xác suất như deep Boltzmann machines có thể được sử dụng để tạo ra biểu diễn từ không gian tiềm ẩn (latent space), cũng cho phép tạo ra dữ liệu bị thiếu từ một trong các phương tiện. Biểu diễn tuần tự (Sequential representation) được sử dụng để xử lý dữ liệu có độ dài biến đổi, chẳng hạn như câu hoặc đoạn âm thanh, thường là với RNNs.
*Coordinated representations* được học bằng cách sử dụng sự giống nhau giữa các phương tiện và ràng buộc. Các mô hình tương tự (Similarity models) có thể buộc biểu diễn của từng phương tiện phải gần nhau, chẳng hạn như từ “car” nên gần hơn với một bức ảnh của xe hơn là của một chiếc thuyền. Không gian tọa độ có cấu trúc sử dụng nén dựa trên hashing, điều này ràng buộc việc đặt dữ liệu embedded modal. 

**Translation** được sử dụng để ánh xạ một phương tiện sang một phương tiện khác, chẳng hạn như tạo chú thích văn bản từ dữ liệu hình ảnh hoặc video. Các nhiệm vụ (tasks) này được phân loại là *Example-based* hoặc *Generative*. 
*Example-based* translation sử dụng tra cứu từ điển để tìm một giá trị phù hợp trong một phương tiện khác. Ngoài từ điển, các tìm kiếm k-nearsest neighbor đã được sử dụng để thực hiện việc retrieval dựa trên consensus. Cả hai phương pháp đều bị hạn chế bởi dữ liệu phương tiện cụ thể mà chúng có khi đào tạo.
*Generative* translation có thể tạo ra các giá trị mới được dịch từ phương tiện gốc thay vì chỉ retrieval đơn giản. Các giải pháp dựa trên ngữ pháp có thể tạo ra văn bản cho phương tiện đích sử dụng các khái niệm cấp cao trong phương tiện nguồn nhưng chỉ gói gọn trong các quy tắc ngữ pháp được xác định trước. Các mạng mã hóa - giải mã (Encoder-decoder networks) mã hóa dữ liệu phương tiện nguồn (source modality data) rồi có thể sau đó được giải mã thành các ví dụ trong phương tiện đích. Các tasks như chuyển đổi giọng nói thành văn bản có thể sử dụng các phương tiện sinh liên tục bằng cách lấy mẫu không gian tiềm ẩn (latent space) chung cho cả hai phương tiện.

**Alignment** tìm các thành phần phụ tương ứng giữa mỗi phương tiện. Điều này thường được thực hiện cho việc retrieval đa phương tiện như đồng bộ hóa âm thanh với khung hình video hoặc đánh dấu hình ảnh bao gồm một cá nhân cụ thể. Các kỹ thuật căn chỉnh đã được xác định là *Explicit* hoặc *Implicit*.
*Explicit* alignment được sử dụng khi mục tiêu là căn chỉnh nhiều phương tiện dựa trên các thành phần liên quan. Các căn chỉnh không giám sát (unsupervised alignments) không sử dụng nhãn nhưng dựa vào các độ đo similarity, chẳng hạn như khớp các chuỗi gen. Các phương pháp học có giám sát cũng có thể được sử dụng nếu các alignment modal được gắn nhãn.
*Implicit alignment* được sử dụng khi specific alignment không được biết và đã được sử dụng với các nhiệm vụ như nhận dạng giọng nói và dịch. Một cách tiếp cận là sử dụng các mô hình đồ thị nơi cấu trúc của các mối quan hệ ngôn ngữ được ánh xạ vào dữ liệu âm thanh. Các mạng nơ-ron sử dụng mã hóa - giải mã và các mô hình dựa trên attention đã được sử dụng để căn chỉnh dữ liệu âm thanh - video bằng cách sử dụng không gian tiềm ẩn (latent space).

<<<<<<< HEAD
**Fusion** là phương pháp kết hợp dữ liệu từ nhiều phương tiện trước khi áp dụng thuật toán. Kết hợp dữ liệu là khái niệm cốt lõi của tất cả các phương pháp đa phương tiện và được nhóm thành các giải pháp *Model-agnostic* và Model-based.
*Model-agnostic* sử dụng các bộ phân loại đơn phương tiện với các kỹ thuật kết hợp early, late và hybrid, điều này cũng đã được thảo luận bởi Di Mitri cùng cộng sự [19] và Simonetta cùng cộng sự [86]. Early fusion kết hợp dữ liệu phương tiện trước khi phân loại, late fusion thực hiện việc specific learning cho phương tiện trước khi kết quả được kết hợp, và hybrid fusion sử dụng sự kết hợp của cả hai.
*Model-based* được thiết kế để giải quyết việc kết hợp phương tiện một cách trực tiếp hơn so với các phương pháp Model-agnostic, mà không tính đến các mối quan hệ giữa các phương tiện. Multi kernel learning, deep belief networks và các mô hình mạng nơ-ron đã được sử dụng cho việc kết hợp đa phương tiện trong khi xem xét tất cả các phương tiện.

**Co-learning** sử dụng kiến thức từ một phương tiện để hỗ trợ việc học của một phương tiện khác. Phương pháp này có thể giải quyết vấn đề dữ liệu bị thiếu hoặc chất lượng thấp trong một phương tiện bằng cách sử dụng dữ liệu chất lượng cao từ phương tiện. Có ba phương pháp Co-learning được xác định là *Parallel*, *Non-parallel* và *Hybrid*.

*Parallel* sử dụng dữ liệu từ các ví dụ được chia sẻ trên nhiều phương tiện cùng một lúc. Co-training sử dụng thông tin từ một phương tiện được gán nhãn tốt để tạo ra nhãn bị thiếu cho phương tiện khác. Học chuyển giao (Transfer learning) có thể sử dụng dữ liệu từ một mô hình song song để thực hiện các nhiệm vụ mới tương tự.

*Non-parallel* không cần các mẫu phương tiện chung chỉ cần các khái niệm chung. Giống như với các mô hình Parallel, học chuyển giao (transfer learning) có thể được sử dụng cũng như học không qua giám sát, có thể xác định các lớp chưa từng thấy. Định vị khái niệm là một kỹ thuật học ý nghĩa ngữ nghĩa từ nhiều phương tiện trong một không gian tiềm ẩn chung.

*Hybrid* sử dụng hai phương tiện non-parallel được kết nối bằng một phương tiện hoặc tập dữ liệu chung. Điều này đã được sử dụng cho việc ghi chú ảnh đa ngôn ngữ, nơi dữ liệu ảnh được chia sẻ giữa các mô hình dựa trên ngôn ngữ khác nhau.

### Giải pháp cho từng lĩnh vực cụ thể

Ứng dụng phổ biến của học đa phương tiện là cảm biến từ xa với hình ảnh siêu phổ từ vệ tinh. Phương pháp này thu thập dữ liệu hình ảnh từ khu vực muốn nhắm đến bằng cách sử dụng nhiều bước sóng ánh sáng như RGB chuẩn, hồng ngoại, hoặc công nghệ chụp ảnh như LiDAR. Trong một bài báo tổng quan [30], các phương pháp học đa nhân đã được nghiên cứu để phân loại hình ảnh. Các phương pháp sử dụng nhân (kernel) này ánh xạ dữ liệu đầu vào vào không gian đặc trưng mới mà sau đó có thể được sử dụng bởi các bộ phân loại dựa trên SVM, tạo ra kết quả tương tự như kiến trúc hợp nhất muộn (late fusion architectures), như sau đây sẽ thảo luận trong Mục [3.3]. Tập trung vào các phương pháp học sâu, Audebert và cộng sự đã đề cập đến các mạng khác nhau được thiết kế cho việc phân loại siêu phổ. Các tác giả đã quan sát thấy rằng các phương pháp 2-D hoạt động tốt trên dữ liệu có mối quan hệ không gian và các phương pháp 3-D cho dữ liệu siêu phổ nơi chiều thứ ba biểu diễn các chế độ hình ảnh. Cũng có đề xuất rằng các mô hình hỗn hợp Gaussian và GAN có thể được sử dụng để tăng cường dữ liệu huấn luyện bằng cách xấp xỉ không gian nhúng. Kết quả của Cuộc thi Geoscience and Remote Sensing Society Data Fusion Contest IEEE năm 2017 cho thấy rằng tất cả các đội hàng đầu đều sử dụng dữ liệu từ nhiều nguồn và sử dụng các phương pháp tổ hợp.

Trong một nghiên cứu mới, học đa phương tiện cũng đã được áp dụng vào hình ảnh y tế. Ngày nay, việc kết hợp nhiều phương pháp chụp hình như chụp cắt lớp vi tính (CT), chụp cộng hưởng từ (MRI), hoặc chụp phát xạ positron (PET) để cung cấp thông tin bổ sung cho việc xác định chẩn đoán hoặc quyết định phương pháp điều trị là rất phổ biến. Một số kiến trúc hợp nhất hình ảnh đã được Huang và cộng sự [40] xem xét, và họ nhận thấy rằng hiện tại có một hạn chế là ít phương pháp hợp nhất sử dụng nhiều hơn hai phương tiện hình ảnh cùng một lúc. Một cuộc khảo sát do Haskins và cộng sự [35] thực hiện cũng đã bao gồm việc hợp nhất hình ảnh y tế trong khi so sánh giữa các kỹ thuật rigid và deformable registration. Để giải quyết vấn đề về các biến dạng hình ảnh không thực tế được sử dụng cho việc non-linear image registrations, GANs đã được đề xuất, vì chúng thường có thể học cách tạo ra các hình ảnh tổng hợp có vẻ hợp lý. Trong cả hai bài báo, người ta đề cập rằng thiếu các tiêu chí đánh giá chuẩn khiến việc đánh giá chính xác các phương pháp hợp nhất hình ảnh trở nên khó khăn. Lĩnh vực chụp ảnh não cũng đã sử dụng hình ảnh đa phương tiện để nâng cao hiểu biết khoa học và hiệu suất chẩn đoán [18], bao gồm hai cuộc khảo sát [68, 80] tập trung vào bệnh Alzheimer.

Một vấn đề khác chúng ta phải đối mặt trong học đa phương tiện đó là theo vết hành vi con người. Với chi phí và kích thước giảm, các cảm biến có thể mặc được bao gồm micro, gia tốc kế và GPS hiện đã có thể sử dụng được. Trong một công trình [76], các kỹ thuật học sâu cho nhận dạng hoạt động và ngữ cảnh đã được nghiên cứu. Nhiều kiến trúc mạng nơ-ron với các phương pháp kết hợp truyền thống early và late đã được đánh giá cũng như các phương pháp trích xuất đặc trưng và kết hợp dữ liệu đa phương tiện khác nhau. Các tác giả cũng đề cập đến một thách thức với việc trích xuất đặc trưng, khi không rõ liệu dữ liệu tín hiệu nên được xử lý như các điểm miền thời gian hay được xử lý thêm bằng các phương pháp như Biến đổi Fourier nhanh (FFT). Trong một cuộc khảo sát khác [27], các cảm biến đã được sử dụng để theo dõi các điều kiện sức khỏe tâm thần với các thuật toán học máy truyền thống. Dựa trên các phương tiện được sử dụng trong các hệ thống phát hiện căng thẳng của tài xế trước đây, Rastgoo và cộng sự [79] đã đề xuất một khung đa phương tiện sử dụng nhiều loại cảm biến khác nhau.

Các khảo sát về các lĩnh vực cụ thể bao gồm sinh trắc học, phân loại ảnh 3-D và xử lý thông tin âm nhạc. Lĩnh vực sinh trắc học sử dụng các đặc điểm của con người, như hình ảnh khuôn mặt, tai hoặc dấu vân tay, để xác định danh tính của cá nhân. Oloyede và Hancke [70] đã xem xét các kiến trúc đa phương tiện và các phương pháp kết hợp dữ liệu cho lĩnh vực này. Griffiths và Boehm [29] cũng đã khảo sát các công trình về phân loại đối tượng 3-D sử dụng đầu vào đa phương tiện. Bằng cách sử dụng các biểu diễn khác nhau của các đối tượng, như với các hình ảnh 2-D chụp từ nhiều góc độ hoặc hình ảnh RGB kết hợp chiều sâu (RGB-D), các mô hình đa phương tiện đã được sử dụng cho việc nhận dạng. Ngoài việc trình bày nhiều kiến trúc mạng khác nhau, người ta cũng quan sát thấy rằng các mô hình 2-D đa phương tiện có thể hoạt động tốt trên một nhiệm vụ 3-D, đặc biệt là khi các mạng 2-D được huấn luyện trước đã chín muồi hơn so với các mạng 3-D. Zhang và cộng sự [123] cũng đã thực hiện một cuộc khảo sát về nghiên cứu sử dụng dữ liệu ảnh đa phương tiện như RGB-D cho việc phân đoạn ảnh. Trong bối cảnh xử lý âm nhạc, Simonetta và cộng sự [86] đã khám phá các bước tiền xử lý như đồng bộ hóa phương tiện, các phương pháp trích xuất đặc trưng và việc chuyển đổi nhiều phương tiện thành không gian đặc trưng chung.

## Hệ thống phân loại đa phương tiện

Một thách thức hiện tại với nghiên cứu về học đa phương tiện là sự pha trộn rộng lớn của các thuật ngữ mô tả các khía cạnh khác nhau của quá trình học. Nhiều bài báo đã được thảo luận trước đây sử dụng các thuật ngữ như early, late, intermediate, hoặc hybrid để mô tả các kiến trúc, nhưng định nghĩa của chúng không phải lúc nào cũng giống nhau. Ngày nay, những người thực hiện phương pháp học sâu quen thuộc với các mạng được mô tả theo các thuật ngữ CNNs, GANs hoặc fully connected neural networks, nhưng những thứ đó không xuất hiện trong kiến trúc phân loại đa phương tiện. Các phân loại trước đây thường là cụ thể cho một lĩnh vực hoặc chung cho tất cả các hệ thống học đa phương tiện, vì vậy khả năng áp dụng của chúng cho các vấn đề phân loại đa phương tiện tùy ý bị giới hạn.

Hệ thống phân loại được trình bày bởi Ramachandram và Taylor [77] được căn chỉnh gần nhất với việc phân loại, tuy nhiên, nó chỉ tập trung vào học sâu và có thể không đủ cụ thể để mô tả hoàn toàn các pipeline đa phương tiện hiện tại. Để giải quyết một số thách thức này, chúng tôi đề xuất một phân loại mới cho phân loại đa phương tiện cung cấp một tập hợp thuật ngữ mô tả ở cấp độ cao có thể được sử dụng để mô tả hoàn toàn các kiến trúc mô hình hiện có hoặc tương lai. Bảng 2 cung cấp danh sách gồm năm giai đoạn chính được sử dụng bởi phân loại này và Bảng 3 bao gồm các chủ đề khác quan trọng khi mô tả kiến trúc đa phương tiện.

Từ các công trình đã được xem xét trong Bảng 4 và 5 và các cuộc khảo sát kể từ năm 2017, chúng tôi đề xuất một phân loại với năm giai đoạn chính được sử dụng để xây dựng các mô hình phân loại đa phương tiện: Tiền xử lý (Preprocessing), Trích xuất Đặc trưng (Feature Extraction), Hợp nhất Dữ liệu (Data Fusion), Học viên Chính (Primary Learner) và Phân loại Cuối cùng (Final Classifier). Trong Phần 4, chúng tôi trình bày nghiên cứu gần đây sử dụng các thuật ngữ này, thảo luận về một số kịch bản nơi nhiều khái niệm kiến trúc được sử dụng trong một kiến trúc đa phương tiện duy nhất và nơi mô tả kiến trúc chính xác là chủ quan hơn.
								Bảng 2: Danh sách gồm năm giai đoạn mà phân loại này
								 sử dụng để mô tả kiến trúc phân loại đa phương tiện
![[2.png]]
								Bảng 3: Các chủ đề khác ngoài các giai đoạn phân loại
								 cần được thảo luận khi mô tả kiến trúc đa phương tiện.
![[3.png]]
### Tiền xử lý (Preprocessing)

Mặc dù không phải lúc nào cũng cần thiết, nhưng nhiều mô hình phân loại đòi hỏi một số bước tiền xử lý, như xử lý dữ liệu bị thiếu, cắt ảnh, lọc nhiễu, hoặc cân bằng lớp. Ở đây, chúng tôi mô tả tiền xử lý là một bước làm sạch dữ liệu, được thực hiện với một số mức độ chuyên môn trong miền dữ liệu và có thể khó để tổng quát hóa trong phân loại này. Trong khi có nhiều cách để làm sạch dữ liệu đơn biến, thì còn nhiều lựa chọn hơn với dữ liệu đa biến nếu mỗi biến được xử lý riêng rẽ. Ví dụ, nếu sử dụng dữ liệu ảnh chụp cắt lớp vi tính (CT) và chụp cộng hưởng từ (MRI), thì có thể cần những chiến lược khác nhau cho việc cắt, co giãn, và giảm nhiễu. Những ảnh này cũng có thể cần được đăng ký, hay căn chỉnh, bằng một phép biến đổi cứng hoặc linh hoạt. Tuy nhiên, tất cả các bước tiền xử lý có thể được bỏ qua cho một hoặc cả hai biến để sử dụng dữ liệu thô. Bởi vì công việc này rất phụ thuộc vào người dùng và miền dữ liệu, bước tiền xử lý không được thảo luận chi tiết hơn nhưng nên được xem xét trong thực tế trên từng trường hợp cụ thể.

### Trích xuất đặc trưng (Feature Extraction)

Mỗi mô hình phân loại đa phương tiện đều sử dụng quá trình lựa chọn đặc trưng ở một mức độ nào đó, có thể bao gồm kỹ thuật chế tạo đặc trưng thủ công, phương pháp học sâu, hoặc là một phần cố hữu của thuật toán phân loại. Quá trình lựa chọn đặc trưng có thể được thực hiện độc lập cho mỗi phương tiện hoặc là một phần của nhiều bước trong kiến trúc mô hình tổng thể. Các phương pháp học sâu như CNN thường được sử dụng để trích xuất đặc trưng nhưng cùng một mạng cũng có thể thực hiện bước học chính, do đó thực hiện hai tác vụ cùng một lúc. Mặc dù các bộ phân loại như Random Forests có thể thực hiện quá trình lựa chọn đặc trưng bằng cách xác định các điểm cắt hữu ích nhất trong quá trình tạo ra cây quyết định, quá trình này có thể được thực hiện ở một bước rõ ràng, chẳng hạn như với CNN để trích xuất đặc trưng ảnh theo sau là bộ phân loại FCNN. Giảm chiều dữ liệu sử dụng Phân tích thành phần chính (PCA) hoặc Phân tích biệt thức tuyến tính (LDA) có thể được sử dụng như một phần của quá trình lựa chọn đặc trưng, thường được sử dụng trong các mô hình học máy truyền thống có thể gặp khó khăn với dữ liệu có số chiều rất cao.

![[4.png]]
									Hình 1: Một ví dụ cho kiến trúc mô hình phân loại đa phương tiện
																	sử dụng early fusion
### Hợp nhất dữ liệu (Data Fusion)

Data Fusion là một khía cạnh độc đáo của học đa phương tiện, nơi thông tin từ các nguồn dữ liệu khác nhau cần được kết hợp khi xây dựng một mô hình chung. Quá trình này có thể xảy ra ngay sau khi dữ liệu đầu vào được biểu diễn, ngay trước khi phân loại cuối cùng, hoặc nhiều lần ở giữa. Các thuật ngữ thường được sử dụng cho các kiến trúc này bao gồm early fusion hoặc late fusion, nhưng các thuật ngữ này có thể không đủ để mô tả hoàn toàn một mô hình đa phương tiện. Vì các công trình trước đây đã trình bày các phương pháp hợp nhất khác nhau, chúng tôi đề xuất một loạt các định nghĩa sẽ được sử dụng trong toàn bộ bài viết này.

#### *Fusion Architecture*

Early fusion xảy ra khi tất cả dữ liệu đa phương tiện được hợp nhất trước khi mô hình học chính được thực hiện. Như hình 1 minh họa, dữ liệu từ hai hoặc nhiều phương tiện được kết hợp và sau đó được truyền vào thuật toán. Một trong những cách phổ biến nhất để đạt được loại hợp nhất này đơn giản là nối dữ liệu phương tiện đầu vào, có thể bao gồm các vector đặc trưng truyền thống hoặc nút đầu ra từ các mạng nơ-ron đã được huấn luyện trước. Mỗi phương tiện cũng có thể đại diện cho một kênh khác nhau trong mô hình CNN, và phương pháp hợp nhất sớm này có thể phù hợp nhất khi có mối liên kết mạnh mẽ giữa mỗi nguồn dữ liệu. Ví dụ, bộ dữ liệu điều trị bằng tia X với hình ảnh (CT) và khối lượng liều dự tính có thể được xếp chồng lên nhau dưới dạng kênh CNN, vì mỗi phương tiện thường có mối quan hệ voxel (pixel 3-D) một-một. Hình ảnh vệ tinh sử dụng các bước sóng ánh sáng khác nhau cũng có thể được hợp nhất theo cách tương tự nếu mỗi phương tiện đại diện cho cùng một khu vực.

Late Fusion thực hiện việc trích xuất đặc trưng độc lập cho từng phương tiện trước khi phân loại cuối cùng, như được thể hiện trong Hình 2. Đầu ra từ giai đoạn hợp nhất có thể bao gồm các đặc trưng học tập ở mức thấp với các mạng sâu hoặc xác suất lớp từ các thuật toán phân loại đầy đủ. Trong cả hai trường hợp, kết quả học được kết hợp để phân loại cuối cùng. Kiến trúc này có lợi từ khả năng huấn luyện từng phương tiện với một thuật toán cụ thể và có thể làm cho việc thêm hoặc trao đổi các phương tiện khác nhau trong tương lai dễ dàng hơn. Một nhược điểm là thiếu chia sẻ dữ liệu giữa các phương tiện, điều này có thể cản trở việc học các mối quan hệ giữa các phương tiện.

Cross-modality Fusion cho phép chia sẻ dữ liệu cụ thể của từng phương tiện trước hoặc trong quá trình học chính. Không giống như early fusion hoặc late fusion, phương pháp này cung cấp một cách để mỗi phương tiện có thể sử dụng ngữ cảnh của nhau để cải thiện khả năng dự đoán của mô hình tổng thể. Việc chia sẻ dữ liệu này có thể được biểu diễn bằng nhiều cách bao gồm ở các phần khác nhau của quá trình học, loại hoặc lượng dữ liệu được chia sẻ, hoặc các phương tiện nào tham gia vào việc chia sẻ. Hình 3 cho thấy một kiến trúc chia sẻ dữ liệu giữa từng phương tiện một lần trước khi hợp nhất, và Hình 4 cho thấy việc chia sẻ dữ liệu xảy ra nhiều lần trong quá trình huấn luyện. Một số bài báo đã trình bày cho thấy loại chia sẻ dữ liệu này có thể vượt trội hơn các phương pháp early fusion hoặc late fusion truyền thống, đề xuất một hướng đi hứa hẹn cho việc giải quyết các vấn đề đa phương tiện. Trong một công trình phân loại hình ảnh vệ tinh [39], mỗi phương tiện được huấn luyện một phần bằng CNN, và kết quả được hợp nhất với dữ liệu gốc từ phương tiện khác. Một tập hợp các CNN khác được sử dụng để tiếp tục học các đặc trưng kết hợp, và kết quả được hợp nhất lại trước khi thực hiện phân loại cuối cùng. Tương tự như kiểu chia sẻ được thể hiện trong Hình 4, mô hình được trình bày bởi Gao et al. [26] đã chia sẻ các đặc trưng học tập một phần giữa các mạng CNN song song nhiều lần để phân loại bệnh Alzheimer. Kết quả từ giai đoạn cuối của từng mạng cụ thể cho từng phương tiện được nối lại trước khi đưa ra dự đoán. Kiến trúc hợp nhất giữa các phương tiện này cũng thường được sử dụng với các mạng tin tưởng sâu (DBN) hoặc kiểu tự mã hóa [25, 32, 59].

![[5.png]]
											Hình 2: Một ví dụ cho kiến trúc mô hình phân loại đa phương tiện
																				sử dụng late fusion
																				
![[6.png]]
											Hình 3: Một ví dụ cho kiến trúc cross-modality với một hoạt động
																				chia sẻ dữ liệu

![[7.png]]
											Hình 4: Phần đầu tiên cho ví dụ cho kiến trúc cross-modality trong
													đó dữ liệu được chia sẻ nhiều lần trong quá trình học
#### *Data Fusion Technique*
Dựa trên đánh giá của chúng tôi về các công trình nghiên cứu trước đây, chúng tôi đã phân loại các kỹ thuật kết hợp dữ liệu thành hai loại: Concatenation và Merge. Hình 5 cho thấy các biểu diễn trực quan của những phong cách thường được sử dụng.

**Concatenation**: Phương pháp này đơn giản chỉ nối dữ liệu từ các modal để tạo thành một vector đặc trưng duy nhất. Khi sử dụng kỹ thuật này, dữ liệu đầu vào có thể là các đặc trưng thô, vector xác suất lớp, hoặc nút mạng nơ-ron. Các ví dụ về việc nối được thể hiện trong Hình 5(a) cho các đặc trưng học máy truyền thống và trong Hình 5(b) cho các nút mạng nơ-ron.

![[8.png]]
			Hình 5: Một minh họa về các kỹ thuật kết hợp dữ liệu chính (concatenation và merge) với hai modal (màu vàng, màu xanh) và kết quả cuối cùng (màu xanh lá cây). Các đặc trưng học máy truyền thống được mô tả dưới dạng hình vuông, các nút mạng nơ-ron được mô tả dưới dạng hình tròn, và các toán tử hợp nhất đặc trưng được biểu diễn dưới dạng Σ.
**Merge**: Phương pháp này kết hợp dữ liệu từ các phương tiện với logic kinh doanh phức tạp hơn so với việc nối đơn giản. Quá trình hợp nhất thường được thực hiện cho các đặc trưng truyền thống với một toán tử số học (được biểu diễn dưới dạng Σ) biến đổi các giá trị đầu vào thành một vector đặc trưng mới, như được thể hiện trong Hình 5(c). Việc hợp nhất mạng nơ-ron kết nối các nút cụ thể của phương tiện với một lớp hợp nhất đầu ra sử dụng trọng số và sai số của mạng để kết hợp các đặc trưng, như được thể hiện trong Hình 5(d). Mặc dù kỹ thuật hợp nhất thường tạo ra ít đặc trưng hoặc nút đầu ra hơn so với việc mã hóa, nó cũng có thể được sử dụng như một phần của quá trình giải mã.

### Học viên chính (Primary Learner)

Mỗi hệ thống học máy truyền thống hoặc học sâu được thiết kế để trích xuất kiến thức từ dữ liệu đào tạo, thường là trọng số mạng, ranh giới quyết định, hoặc tiêu chí chia. Các pipeline đa phương tiện có thể thực hiện quá trình học này theo nhiều cách, điều này đòi hỏi phải giải thích rõ ràng để hỗ trợ sự tiến bộ trong tương lai và việc tái tạo các thí nghiệm. Ví dụ, các mô hình kết hợp sớm tạo ra một nguồn dữ liệu đã được kết hợp nên quá trình học có thể diễn ra cùng một lúc cho tất cả các phương tiện. Tuy nhiên, late fusion thực hiện việc học độc lập cho mỗi phương tiện, và các mô hình cross-modality có thể thực hiện quá trình học nhiều lần. Công việc được thực hiện bởi giai đoạn Học viên chính (Primary learner) cũng có thể được chia sẻ với giai đoạn Trích xuất Đặc trưng (Feature Extraction) hoặc Phân loại Cuối cùng (Final Classifier), điều này sẽ được thảo luận kỹ hơn trong Mục [3.6].

### Phân loại cuối cùng (Final Classifier)

Khác với giai đoạn Học viên chính (Primary Learner), Phân loại Cuối (Final Classifier) cùng được sử dụng để tạo ra kết quả cuối cùng của pipeline đa phương tiện, thường là nhãn dự đoán hoặc lớp vector xác suất. Thuật toán được sử dụng cho giai đoạn này có thể giống như thuật toán được sử dụng cho Học viên chính (Primary Learner), một thuật toán hoàn toàn khác, hoặc công việc có thể được chia sẻ giữa hai giai đoạn. Các thuật toán được sử dụng tại giai đoạn này có thể từ một lớp softmax duy nhất đến các mô hình tập hợp toàn diện. Chúng tôi tin rằng việc xác định rõ ràng giai đoạn này giúp dễ dàng mô tả kiến trúc đa phương tiện tổng thể của một mô hình mới có thể được triển khai bởi các nhà nghiên cứu trong tương lai.

![[9.png]]
					Hình 6: Một ví dụ về kiến trúc đa phương tiện sử dụng phương pháp late fusion, trong đó các tác vụ trích xuất đặc trưng và học được thực hiện bằng một mô hình chung.
![[10.png]]
					Hình 7: Một ví dụ về kiến trúc đa phương tiện sử dụng phương pháp early fusion, trong đó các tác vụ học và phân loại được thực hiện bằng một mô hình chung.

**Fusion** là phương pháp kết hợp dữ liệu từ nhiều modal trước khi áp dụng thuật toán. Kết hợp dữ liệu là khái niệm cốt lõi của tất cả các phương pháp đa modal và được nhóm thành các giải pháp *Model-agnostic* và Model-based.
*Model-agnostic* sử dụng các bộ phân loại đơn modal với các kỹ thuật kết hợp early, late và hybrid, điều này cũng đã được thảo luận bởi Di Mitri cùng cộng sự [19] và Simonetta cùng cộng sự [86]. Early fusion kết hợp dữ liệu modal trước khi phân loại, late fusion thực hiện việc specific learning cho modal trước khi kết quả được kết hợp, và hybrid fusion sử dụng sự kết hợp của cả hai.
*Model-based* được thiết kế để giải quyết việc kết hợp modal một cách trực tiếp hơn so với các phương pháp Model-agnostic, mà không tính đến các mối quan hệ giữa các modal. Multi kernel learning, deep belief networks và các mô hình mạng nơ-ron đã được sử dụng cho việc kết hợp đa modal trong khi xem xét tất cả các modal.