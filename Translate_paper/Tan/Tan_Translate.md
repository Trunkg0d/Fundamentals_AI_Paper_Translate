# Multimodal Classification: Current Landscape, Taxonomy and Future Directions
[WILLIAM C.SLEEMAN IV, RISHABH KAPOOR], and [PREETAM GHOSH],
Virginia Commonwealth University, USA

Nghiên cứu về Multimodal Classification đã đạt được nhiều thành tựu trên những bộ dữ liệu mới trong nhiều lĩnh vực khác nhau như hình ảnh vệ tinh, sinh trắc học, y tế. Những nghiên cứu trước đã chỉ ra lợi ích của việc kết hợp dữ liệu từ nhiều nguồn so với dữ liệu unimodal truyền thống đã dẫn đến sự phát triển của nhiều cấu trúc multimodal chưa từng có trước đây. Tuy nhiên, việc thiếu nhất quán các thuật ngữ và mô tả về kiến trúc gây không ít khó khăn cho việc so sánh khác giải pháp với nhau. Chúng tôi đối mặt với thách thức đó bằng việc đề xuất một cách thức phân loại mới để mô tả những mô hình multimodal classification dựa trên các xu hướng được tìm thấy trong các công bố gần đây. Các ví dụ về cách phân loại này có thể được áp dụng trong các mô hình hiện có mà đã được trình bày và cũng được xem như là một danh sách để hỗ trợ trình bày một cách rõ ràng và đầy đủ các mô hình trong tương lai. Nhiều khía cạnh khó nhất của unimodal classification vẫn chưa được giải quyết một cách đầy đủ cho các bộ dữ liệu multimodal bao gồm cả dữ liệu lớn (big data), sự mất cân đối lớp (class imbalance) và sự khó khăn trong việc phân loại từng trường hợp cụ thể trong tập dữ liệu (instance-level difficulty). Chúng tôi sẽ thảo luận về những thách thức này và những hướng nghiên cứu trong tương lai.
## GIỚI THIỆU (INTRODUCTION)
Trong thập kỷ qua, đã có sự tập trung tăng cường vào việc kết hợp dữ liệu từ nhiều phương thức khác nhau để cải thiện các mô hình phân loại dựa trên học máy (machine learning). Dữ liệu đang trở nên quan trọng hơn đối với mọi ngành công nghiệp và nghiên cứu, điều này dẫn đến việc tạo ra các tập dữ liệu lớn và đa dạng hơn. Tốc độ thu thập dữ liệu ngày càng tăng và những lợi ích được báo cáo của dữ liệu đa phương tiện (multimodal data) cho các mô hình học máy (machine learning) đã thúc đẩy sự quan tâm cho lĩnh vực này. Bằng cách sử dụng thông tin từ nhiều biểu diễn của cùng một chủ đề, một bức tranh hoàn chỉnh hơn về vấn đề đang được giải quyết có thể được xây dựng. Dữ liệu trên đa lĩnh vực có thể được biểu diễn một cách tự nhiên trong nhiều lĩnh vực vấn đề như y tế [27, 35, 40, 49], hình ảnh siêu không gian [7, 30], phân tích cảm xúc [14, 83, 89] và nhiều lĩnh vực khác.

Đa số các thuật toán phân loại hiện nay được thiết kế cho các tập dữ liệu đơn phương tiện (unimodal datasets), đại diện cho một nguồn dữ liêu duy nhất cho mỗi vấn đề cụ thể. Những tập dữ liệu này thường chỉ sử dụng một loại dữ liệu như bảng, hình ảnh, hoặc văn bản nhưng nhiều tình huống trong thực tế bao gồm dữ liệu của nhiều lại khác nhau. Các tập dữ liệu dự đoán giá có thể bao gồm cả văn bản từ các bài báo và dữ liệu bảng từ các báo cáo tài chính, hoặc hồ sơ y tế có thể có cả dữ liệu giám sát tim dựa trên tín hiệu và chẩn đoán hình ảnh. Việc kết hợp các phương thức dữ liệu có thể gặp thách thức khi mà mỗi biểu diễn riêng đều khác biệt đáng kể so với dữ liệu đã kết hợp như là hình ảnh-văn bản, âm thanh-video, hoặc nhiều cảm biến không đông bộ theo thời gian. Những thách thức đó dẫn đến những giải pháp sử dụng các thuật toán đơn phương tiện (unimodal algorithms) để giải quyết các vấn đề đa phương tiện (multimodal problems).

Học đa phương tiện (multimodal learning) ngày càng được quan tâm dẫn đến một số lượng các bài khảo sát gần đây bao phủ toàn bộ các lĩnh vực [9, 59, 122, 124], với nhiều bài khảo sát tập trung vào lĩnh vực học sâu (deep learning) [32, 77, 115], giải pháp cụ thể cho từng lĩnh vực [7, 27, 29], hoặc các phương pháp không phân loại [35, 49, 78]. Mặc dù những công trình này bao phủ sự rộng lớn của học đa phương tiện (multimodal learing), nhưng không có bất kỳ bài khảo sát nào cụ thể đi nghiên cứu các vấn đề phân loại hay các thuộc tính đặc trưng của chúng.  Bài báo này được dẫn dắt bởi các động lực sau:
	(1) **Thiếu một hệ thống phân loại cụ thể cho phân loại đa phương tiện**
	Mặc dù đã có nhiều hệ thống phân loại được trình bày trước đây, nhưng chúng được hướng đến việc học đa phương tiện (multimodal learning) toàn diện thay vì phân loại. Ví dụ, công trình của Baltrušaitis và cộng sự [9] đề cập đến nhiều lại học như chú thích hình ảnh (image captioning), mô tả video (video description), chuyển đổi văn bản thành hình ảnh (text-to-image conversions), đồng huấn luyện (co-traning), học chuyển giao (transfer learning) và học không cần ví dụ (zero-shot learning).  Mặc dù hệ thống phân loại đó có thể được áp dụng cho hầu như bất kỳ vấn đề đa phương tiện (multilmodal problem) nào, nhưng nó không đủ cụ thể để mô tả đầy đủ các kiến trúc phân loại đa phương tiện (multimodal classfification) gần đây.
	(2) **Xác định xu hướng gần đây trong kiến trúc mô hình**
	Vì các bài khảo sát trước đây đã tập trung vào các khía cạnh cấp cao của học đa phương tiện (multimodal learning) hoặc các vấn đề cụ thể cho từng lĩnh vực, do đó chưa có một bài đánh giá về các mô hình phân loại gần đây và kiến trúc của chúng. Việc so sánh các kiến trúc là cần thiết để xác định xu hướng hiện tại và cách chúng có thể được mô tả bằng một hệ thống phân loại chung.
	(3) **Cung cấp một cách để mô tả kiến trúc phân loại đa phương tiện (multimodal classificaiton)**
	Trong quá trình xem xét các bài báo về phân loại đa phương tiện (multimodal classification), chúng tôi nhận thấy rằng cần một lượng công việc đáng kể để phân rã nhiều kiến trúc mô hình. Mỗi mô hình sử dụng bộ thuật ngữ và phương thức trình bày riêng, vì vậy việc xem xét từng bài báo là một trải nghiệm mới khiến quá trình này khó khăn hơn. Đi cùng hệ thống phân loại, cần có một khung mô tả chung để làm cho việc mô tả và so sánh các kiến trúc mô hình trở nên dễ dàng hơn.
	(4) **Thảo luận về các thách thức trong tương lai**
	Các vấn đề liên quan đến dữ liệu lớn (big data), tính toán phân tán (distributed computing), và các tập dữ liệu khó đã được nghiên cứu kỹ lưỡng với các vấn đề đơn phương tiện (unimodal problems), nhưng vẫn còn hạn chế trong học đa phương tiện (multimodal learning). Cần có một cuộc thảo luận về các thách thức này có thể ảnh hưởng đến phân loại đa phương tiện (multimodal classification) như thế nào.

Phần còn lại của bài báo được tổ chức như sau: Phần 2 cung cấp một cái nhìn tổng quát  cho học đa phương tiện (multimodal learning) và ví dụ về các giải pháp trong từng lĩnh vực cụ thể hiện có. Phần 3 đưa ra các mô tả về kiến trúc phân loại đa phương tiện (multimodal classification) và hệ thống phân loại mà chúng tôi đã đề xuất, và phần 4 xem xét nghiên cứu phân loại đa phương tiện (multimodal classification) gần đây sử dụng những thuật ngữ chung, thứ sẽ giải quyết động lực 1 và 2 ở trên. Phần 5 đưa ra các ví dụ về cách áp dụng hệ thống phân loại cho cả các mô hình hiện có và tương lại trong động lực 3. Phần 6 thảo luận về những thách thức với việc phân loại mà chưa được giải quyết cho các vấn đề đa phương tiện (multimodal problems) đã nêu trong động lực 4. Cuối cùng, Phần 7 cung cấp những nhận xét kết luận của chúng tôi. Trong bảng 1, chúng tôi giới thiệu một danh sách các từ viết tắt sẽ được sử dụng thường xuyên trong phần còn lại của bài viết này.
![[Translate_paper/Tan/images/1.png]]
## Các nghiên cứu đa phương tiện trước đây
Lợi ích tiềm năng của việc sử dụng thông tin từ nhiều nguồn dữ liệu đã dẫn đến nhiều bài báo gần đây tập trung vào học đa phương tiện (multimodal learning). Trong phần này, chúng tôi xem xét các khái niệm cốt lõi của học đa phương tiện, phân loại và nghiên cứu cụ thể theo lĩnh vực. 
Tuy nhiên, trước hết chúng tôi phải thảo luận về các thuật ngữ đa phương tiện (multimodal) và đa quan điểm (multi-view), vì cả hai đều thường được sử dụng trong văn bản. Những thuật ngữ này thường được sử dụng thay thế như là các hệ thống học tập kết hợp thông tin từ nhiều nguồn, thường để phân biệt với các vấn đề truyền thống sử dụng một nguồn dữ liệu duy nhất (đơn phương tiện). Mặc dù những thuật ngữ này được sử dụng để mô tả các mô hình học tập kết hợp rõ ràng nhiều nguồn dữ liệu, đa quan điểm dường như được liên kết phổ biến hơn với các loại thuật toán khác nhau, chẳng hạn như đào tạo cùng nhau [92, 124], Phân tích Tương quan Chuẩn (CCA) -dựa trên truy xuất chéo-modality [59, 124], giám sát bán [124], gom nhóm [15, 50], lựa chọn tính năng không giám sát [99, 100], và học không gian con [110]. 
Vì lý do nhất quán, chúng tôi đã chọn sử dụng thuật ngữ đa phương tiện để mô tả các thuật toán học tập bao gồm thông tin từ nhiều nguồn dữ liệu với mục đích cải thiện hiệu suất dự đoán. Các trường hợp sử dụng khác, chẳng hạn như học chuyển giao hoặc đào tạo cùng nhau, sau đó có thể được mô tả là đa quan điểm để cung cấp một số sự phân biệt giữa những cách tiếp cận học này. Trong khi chúng tôi tin rằng những định nghĩa này sẽ hữu ích cho cộng đồng nghiên cứu, sẽ cần thêm thảo luận để hình thành một sự đồng lòng.
### Khái niệm đa phương tiện
Một số khảo sát đã xác định đồng đào tạo (co-training) [92, 110, 124] và đồng điều chỉnh (co-regularization) [92, 124] là các hạng mục chính của học đa phương tiện (multimodal learning). Đồng đào tạo được sử dụng trong các vấn đề bán giám sát khi có sự kết hợp của dữ liệu có nhãn và không có nhãn, nơi kiến thức từ một phương tiện (modality) có thể được sử dụng để hỗ trợ một mô hình được đào tạo trên một phương tiện khác. Các ứng dụng tiềm năng của đồng đào tạo bao gồm học không qua giám sát, học chuyển giao và ghi chú các ví dụ không có nhãn. Đồng điều chỉnh biến đổi từng phương tiện để đảm bảo rằng chúng tương thích. Điều này có thể được thực hiện với các kỹ thuật như CCA hoặc hiệu chỉnh các bộ phân loại cụ thể cho phương tiện. 
Một công trình toàn diện hơn đã được trình bày bởi Baltrušaitis và cộng sự [9] rằng đã xác định năm thách thức với học đa phương tiện: biểu diễn (representation) [9, 122], dịch (translation) [9], căn chỉnh (alignment) [9, 59, 92], hợp nhất (fusion) [9, 59, 92, 122], và đồng học tập (co-learning) [9, 124]. Một số nhiệm vụ học đa phương tiện khác cũng đã được nghiên cứu bao gồm học bán giám sát [92, 110, 124], mã hóa [25], gom nhóm [92, 124], và học đa nhiệm (multi-task learning) [55, 124]. Mặc dù nhiều khảo sát này giải quyết các khía cạnh của các vấn đề phân loại, chẳng hạn như căn chỉnh và hợp nhất, nhưng chúng thường bao gồm một phạm vi rộng lớn các chủ đề. 
### Mô hình phân loại
Nhiều bài báo đã trình bày các hệ thống phân loại, thường nhắm vào các vấn đề thuộc lĩnh vực cụ thể. Di Mitri và cộng sự [19] đã nghiên cứu việc sử dụng dữ liệu đa phương tiện (multimodal data) để học các hành vi của con người sử dụng cảm biến. Một hệ thống phản hồi được gọi là Mô hình Phân tích Học tập Đa phương tiện (Mulltimodal Learning Analysis Model - MLeAM)  sử dụng dữ liệu cảm biến đa phương tiện, chú thích thủ công và học máy để hướng dẫn các thay đổi về hành vi. Các tác giả cũng cung cấp một hệ thống phân loại dạng cây mô tả các nguồn dữ liệu khác nhau có thể thu thập được từ cảm biến. Garcia-Ceja và cộng sự [27] cũng đã đánh giá các hệ thống dựa trên cảm biến dùng để giải quyết các vấn đề về sức khỏe tinh thần. Hệ thống phân loại của họ đề cập đến loại nghiên cứu, thời gian nghiên cứu và các loại cảm biến.

Yan và cộng sự [15] đã đánh giá các phương pháp đa phương tiện (multimodal methods) trong bối cảnh của học sâu. Hệ thống phân loại của họ phân biệt các thuật toán phụ thuộc vào việc chúng có thuộc về học sâu (tức là CNN, GAN) hay là các kỹ thuật học máy truyền thống đã được chiều chỉnh để phù hợp với học sâu (tức là CCA, spectal clusstering). Bài đánh giá của họ cũng thảo luận về các chiến lược mạng khác nhau, bộ mã tự động hai chiều (bimodal auto-encoders) và các phương pháp dựa trên GAN.

Jiang và cộng sự [49] đã cung cấp một bài đánh giá toàn diện về các kỹ thuật matching hay registration cho đa phương tiện hình ảnh, nó liên kết cùng một khái niệm qua nhiều hình ảnh. Họ cũng đã xác định được hai lớp chính của các giải pháp: image registration dựa trên khu vực và dựa trên đặc trưng. Sử dụng thống tin cường độ của toàn bộ ảnh để tìm các vùng khớp,  các phương pháp dựa trên vùng (area) tạo ra các biến đổi có thể được sử dụng trong việc image registration. Các phương pháp registration dựa trên đặc trưng bao gồm phát hiện đặc trưng (feature detection) (góc, blob và đặc trưng có thể học), mô tả đặc trưng (feature description) (float, nhị phân, và mô tả có thể học) và khớp đặc trưng (feature matching) (graph matching, point set registration, các phương pháp gián tiếp).

Ramachandram và Taylor [77] đã cung cấp một hệ thống phân loại kèm theo bài đánh giá về nghiên cứu đa phương tiện học sâu. Trong hệ thống phân loại của họ, các mô hình được mô tả bằng các modal đầu vào, problem space, fusion method, loại mô hình và kiến trúc. Các modal đầu vào bao gồm âm thanh, video, hình ảnh, văn bản và các modal khác cụ thể cho lĩnh vực y tế. Problem space bao gồm các lĩnh vực như nhận dạng hành động, chẩn đoán y tế và nắm bắt robot. Fusion method mô tả cách dữ liệu từ từng modal được kết hợp và sử dụng các thuật ngữ *early, intermediate* và *late*. Loại mô hình là *generative* hoặc *discriminate*, với kiến trúc được xác định là mô hình thực sự được sử dụng, chẳng hạn như CNN, RNN hoặc LSTM.

Tiếp theo, chúng tôi sẽ cung cấp một cái nhìn tổng quan, ngắn gọn về hệ thống phân loại đa phương tiện được đề xuất bởi Baltrušaitis và cộng sự [9] bao gồm các khái niệm học về representation, translation, alignment, fusion và co-learning.

**Representation** được mô tả là cách dữ liệu từ từng modal được trình bày dưới dạng vector đặc trưng. Vì dữ liệu có thể là văn bản, hình ảnh hoặc video, sự không đồng nhất có thể tạo thêm sự phức tạp cho các learning models. Các thách thức về representation được gom lại thành *Joint* hoặc *Coordinated*. 
*Joint representation*s kết hợp dữ liệu từ nhiều modal để tạo ra một biểu diễn duy nhất. Điều này có thể được thực hiện với các mạng nơ-ron bằng cách nối các lớp cụ thể cho modal để tạo ra một lớp ẩn (hidden layer) mới. Các mô hình đồ thị xác suất như deep Boltzmann machines có thể được sử dụng để tạo ra biểu diễn từ không gian tiềm ẩn(latent space), cũng cho phép tạo ra dữ liệu bị thiếu từ một trong các modal. Biểu diễn tuần tự (Sequential representation) được sử dụng để xử lý dữ liệu có độ dài biến đổi, chẳng hạn như câu hoặc đoạn âm thanh, thường là với RNNs.
*Coordinated representations* được học bằng cách sử dụng sự giống nhau giữa các modal và ràng buộc. Các mô hình tương tự (Similarity models) có thể buộc biểu diễn của từng modal phải gần nhau, chẳng hạn như từ “car” nên gần hơn với một bức ảnh của xe hơn là của một chiếc thuyền. Không gian tọa độ có cấu trúc sử dụng nén dựa trên hashing, điều này ràng buộc việc đặt dữ liệu embedded modal. 

**Translation** được sử dụng để ánh xạ một modal sang một modal khác, chẳng hạn như tạo chú thích văn bản từ dữ liệu hình ảnh hoặc video. Các nhiệm vụ (tasks) này được phân loại là *Example-based* hoặc *Generative*. 
*Example-based* translation sử dụng tra cứu từ điển để tìm một giá trị phù hợp trong một modal khác. Ngoài từ điển, các tìm kiếm k-nearsest neighbor đã được sử dụng để thực hiện việc retrieval dựa trên consensus. Cả hai phương pháp đều bị hạn chế bởi dữ liệu modal cụ thể mà chúng có khi đào tạo.
*Generative* translation có thể tạo ra các giá trị mới được dịch từ modal gốc thay vì chỉ retrieval đơn giản. Các giải pháp dựa trên ngữ pháp có thể tạo ra văn bản cho modal đích sử dụng các khái niệm cấp cao trong modal nguồn nhưng chỉ gói gọn trong các quy tắc ngữ pháp được xác định trước. Các mạng mã hóa - giải mã (Encoder-decoder networks) mã hóa dữ liệu modal nguồn (source modality data) rồi có thể sau đó được giải mã thành các ví dụ trong modal đích. Các tasks như chuyển đổi giọng nói thành văn bản có thể sử dụng các modal sinh liên tục bằng cách lấy mẫu không gian tiềm ẩn (latent space) chung cho cả hai modal.

**Alignment** tìm các thành phần phụ tương ứng giữa mỗi modal. Điều này thường được thực hiện cho việc retrieval đa phương tiện như đồng bộ hóa âm thanh với khung hình video hoặc đánh dấu hình ảnh bao gồm một cá nhân cụ thể. Các kỹ thuật căn chỉnh đã được xác định là *Explicit* hoặc *Implicit*.
*Explicit* alignment được sử dụng khi mục tiêu là căn chỉnh nhiều modal dựa trên các thành phần liên quan. Các căn chỉnh không giám sát (unsupervised alignments) không sử dụng nhãn nhưng dựa vào các độ đo similarity, chẳng hạn như khớp các chuỗi gen. Các phương pháp học có giám sát cũng có thể được sử dụng nếu các alignment modal được gắn nhãn.
*Implicit alignment* được sử dụng khi specific alignment không được biết và đã được sử dụng với các nhiệm vụ như nhận dạng giọng nói và dịch. Một cách tiếp cận là sử dụng các mô hình đồ thị nơi cấu trúc của các mối quan hệ ngôn ngữ được ánh xạ vào dữ liệu âm thanh. Các mạng nơ-ron sử dụng mã hóa - giải mã và các mô hình dựa trên attention đã được sử dụng để căn chỉnh dữ liệu âm thanh - video bằng cách sử dụng không gian tiềm ẩn (latent space).

**Fusion** là phương pháp kết hợp dữ liệu từ nhiều modal trước khi áp dụng thuật toán. Kết hợp dữ liệu là khái niệm cốt lõi của tất cả các phương pháp đa modal và được nhóm thành các giải pháp *Model-agnostic* và Model-based.
*Model-agnostic* sử dụng các bộ phân loại đơn modal với các kỹ thuật kết hợp early, late và hybrid, điều này cũng đã được thảo luận bởi Di Mitri cùng cộng sự [19] và Simonetta cùng cộng sự [86]. Early fusion kết hợp dữ liệu modal trước khi phân loại, late fusion thực hiện việc specific learning cho modal trước khi kết quả được kết hợp, và hybrid fusion sử dụng sự kết hợp của cả hai.
*Model-based* được thiết kế để giải quyết việc kết hợp modal một cách trực tiếp hơn so với các phương pháp Model-agnostic, mà không tính đến các mối quan hệ giữa các modal. Multi kernel learning, deep belief networks và các mô hình mạng nơ-ron đã được sử dụng cho việc kết hợp đa modal trong khi xem xét tất cả các modal.
ádadadđ